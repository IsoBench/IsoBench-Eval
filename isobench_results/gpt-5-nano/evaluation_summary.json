{
  "model_name": "gpt-5-nano",
  "timestamp": "2025-08-09T03:24:06.540350",
  "task_summaries": {
    "math_convexity": {
      "total_samples": 512,
      "correct_samples": 508,
      "overall_accuracy": 0.9921875,
      "modality_breakdown": {
        "text": {
          "total": 256,
          "correct": 255,
          "accuracy": 0.99609375
        },
        "image": {
          "total": 256,
          "correct": 253,
          "accuracy": 0.98828125
        }
      },
      "gap": 0.0078125,
      "log_file": "math_convexity.json"
    },
    "math_parity": {
      "total_samples": 768,
      "correct_samples": 654,
      "overall_accuracy": 0.8515625,
      "modality_breakdown": {
        "text": {
          "total": 384,
          "correct": 378,
          "accuracy": 0.984375
        },
        "image": {
          "total": 384,
          "correct": 276,
          "accuracy": 0.71875
        }
      },
      "gap": 0.265625,
      "log_file": "math_parity.json"
    },
    "math_breakpoint": {
      "total_samples": 512,
      "correct_samples": 495,
      "overall_accuracy": 0.966796875,
      "modality_breakdown": {
        "text": {
          "total": 256,
          "correct": 253,
          "accuracy": 0.98828125
        },
        "image": {
          "total": 256,
          "correct": 242,
          "accuracy": 0.9453125
        }
      },
      "gap": 0.04296875,
      "log_file": "math_breakpoint.json"
    },
    "chemistry": {
      "total_samples": 150,
      "correct_samples": 141,
      "overall_accuracy": 0.94,
      "modality_breakdown": {
        "text": {
          "total": 75,
          "correct": 73,
          "accuracy": 0.9733333333333334
        },
        "image": {
          "total": 75,
          "correct": 68,
          "accuracy": 0.9066666666666666
        }
      },
      "gap": 0.06666666666666676,
      "log_file": "chemistry.json"
    },
    "physics": {
      "total_samples": 150,
      "correct_samples": 125,
      "overall_accuracy": 0.8333333333333334,
      "modality_breakdown": {
        "text": {
          "total": 75,
          "correct": 65,
          "accuracy": 0.8666666666666667
        },
        "image": {
          "total": 75,
          "correct": 60,
          "accuracy": 0.8
        }
      },
      "gap": 0.06666666666666665,
      "log_file": "physics.json"
    },
    "graph_connectivity": {
      "total_samples": 256,
      "correct_samples": 250,
      "overall_accuracy": 0.9765625,
      "modality_breakdown": {
        "text": {
          "total": 128,
          "correct": 128,
          "accuracy": 1.0
        },
        "image": {
          "total": 128,
          "correct": 122,
          "accuracy": 0.953125
        }
      },
      "gap": 0.046875,
      "log_file": "graph_connectivity.json"
    },
    "graph_maxflow": {
      "total_samples": 256,
      "correct_samples": 205,
      "overall_accuracy": 0.80078125,
      "modality_breakdown": {
        "text": {
          "total": 128,
          "correct": 128,
          "accuracy": 1.0
        },
        "image": {
          "total": 128,
          "correct": 77,
          "accuracy": 0.6015625
        }
      },
      "gap": 0.3984375,
      "log_file": "graph_maxflow.json"
    },
    "graph_isomorphism": {
      "total_samples": 256,
      "correct_samples": 195,
      "overall_accuracy": 0.76171875,
      "modality_breakdown": {
        "text": {
          "total": 128,
          "correct": 123,
          "accuracy": 0.9609375
        },
        "image": {
          "total": 128,
          "correct": 72,
          "accuracy": 0.5625
        }
      },
      "gap": 0.3984375,
      "log_file": "graph_isomorphism.json"
    },
    "winner_id": {
      "total_samples": 514,
      "correct_samples": 434,
      "overall_accuracy": 0.8443579766536965,
      "modality_breakdown": {
        "text": {
          "total": 257,
          "correct": 239,
          "accuracy": 0.9299610894941635
        },
        "image": {
          "total": 257,
          "correct": 195,
          "accuracy": 0.7587548638132295
        }
      },
      "gap": 0.1712062256809339,
      "log_file": "winner_id.json"
    }
  },
  "macro_task_summaries": {
    "Math": {
      "text_accuracy": 0.9888392857142857,
      "image_accuracy": 0.8604910714285714,
      "gap": 0.1283482142857143,
      "total_text_samples": 896,
      "total_image_samples": 896,
      "correct_text_samples": 886,
      "correct_image_samples": 771
    },
    "Science": {
      "text_accuracy": 0.92,
      "image_accuracy": 0.8533333333333334,
      "gap": 0.06666666666666665,
      "total_text_samples": 150,
      "total_image_samples": 150,
      "correct_text_samples": 138,
      "correct_image_samples": 128
    },
    "Algorithm": {
      "text_accuracy": 0.9869791666666666,
      "image_accuracy": 0.7057291666666666,
      "gap": 0.28125,
      "total_text_samples": 384,
      "total_image_samples": 384,
      "correct_text_samples": 379,
      "correct_image_samples": 271
    },
    "Game": {
      "text_accuracy": 0.9299610894941635,
      "image_accuracy": 0.7587548638132295,
      "gap": 0.1712062256809339,
      "total_text_samples": 257,
      "total_image_samples": 257,
      "correct_text_samples": 239,
      "correct_image_samples": 195
    }
  },
  "overall_summary": {
    "text_accuracy": 0.973325429756965,
    "image_accuracy": 0.8091286307053942,
    "gap": 0.1641967990515708,
    "total_text_samples": 1687,
    "total_image_samples": 1687,
    "correct_text_samples": 1642,
    "correct_image_samples": 1365
  }
}